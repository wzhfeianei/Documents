# Jmeter的报告是怎么生成的
在抛开的其它复杂的脚本运行代码之前,我们先来看Jmeter的报告相关的源码,在Jmeter中,如果有一份已有的*.jtl报告,可以直接用命令来生成详细的HTML报告文件,进入Jmeter的bin目录,运行cmd后执行命令:`
jmeter -g *.jtl -o report`,就可以直接生成,那么根据这个命令来调试源代码的报告生成逻辑.

## 准备工作
1. 一个经Jmeter执行的结果文件*.jtl,可以直接拷到bin目录下,省下打路径的字符
2. IDEA源码调试环境,看[01-配置Jmeter源码到IDEA环境.md](https://github.com/wzhfeianei/Documents/blob/master/180412-Jmeter%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/01-%E9%85%8D%E7%BD%AEJmeter%E6%BA%90%E7%A0%81%E5%88%B0IDEA%E7%8E%AF%E5%A2%83.md)
## 替换默认命令
进入`NewDriver`类,在main方法替换main的参数,
```Java
        String[] testArgs = new String[]{"-gtest.jtl","-oreport"};
```
并将后面调用args参数替换为testArgs

## 步调
右键`Debug NewDriver.main()`,进入调试模式,可以追踪报告的生成顺序为

1. `NewDriver`中的`invoke`调用了`Jmeter`的`start`方法,内部调用`run`方法
2. 在`Jmeter`中`start()`-->`run()`-->`generateReport()`-->`reportGenerator.generate()`
3. `reportGenerator`为`ReportGenerator`的一个实例,在`ReportGenerator`中如下实现
```Java
 SampleSource source = new CsvFileSampleSource(testFile, CSV_DEFAULT_SEPARATOR);
 //...//
 // Generate data
        log.debug("Start samples processing");
        try {
            source.run(); // NOSONAR
        } catch (SampleException ex) {
            throw new GenerationException("Error while processing samples:"+ex.getMessage(), ex);
        }
        log.debug("End of samples processing");

        log.debug("Start data exporting");
```
4. 进入`CsvFileSampleSource`的`run()`方法

```Java
private PrivateProducer producer;
//中间略//
    @Override
    public void run() {
        produce();
    }
//中间略//
    /**
     * Read all input CSV files and produce their samples on registered sample
     * consumers
     */
    private void produce() {
        SampleContext context = getSampleContext();
        Validate.validState(context != null, "Set a sample context before producing samples.");

        for (int i = 0; i < csvReaders.length; i++) {
            long sampleCount = 0;
            long start = now();
            CsvSampleReader csvReader = csvReaders[i];
            producer.setSampleContext(context);
            producer.setProducedMetadata(csvReader.getMetadata(), i);
            producer.setChannelAttribute(i, SOURCE_FILE_ATTRIBUTE,
                    inputFiles[i]);
            producer.startProducing();
            try {
                Sample s = null;
                while ((s = csvReader.readSample()) != null) {
                    producer.produce(s, i);
                    sampleCount++;
                }
            } finally {
                producer.stopProducing();
                csvReader.close();
            }
            if (LOG.isInfoEnabled()) {
                LOG.info("produce(): " + sampleCount + " samples produced in "
                        + time(now() - start) + " on channel " + i);
            }
        }
    }

//中间略
        @Override
        public void produce(Sample s, int channel) {
            for (SampleConsumer consumer : this.sampleConsumers) {
                try {
                    consumer.consume(s, channel);
                } catch (Exception e) {
                    throw new SampleException("Consumer failed with message :"
                            + e.getMessage(), e);
                }
            }
        }


```

5. `SampleConsumer`为一个接口,在本生成报告中的实际类为`NormalizerSampleConsumer`

```Java
  @Override
    public void consume(Sample s, int channel) {
        Date date = null;
        try {
            String tStr = s.getData(timestamp);
            if(isMillisFormat) {
                date = new Date(Long.parseLong(tStr));
            } else {
                date = dateFormat.parse(tStr);                    
            }
        } catch (Exception e) {
            throw new SampleException(String.format(
                    PARSE_TIMESTAMP_EXCEPTION_MESSAGE, s.getData(timestamp),
                    TIMESTAMP_FORMAT, s.toString()), e);
        }
        long time = date.getTime();
        int cc = sampleMetadata.getColumnCount();
        String[] data = new String[cc];
        for (int i = 0; i < cc; i++) {
            if (i == timestamp) {
                data[i] = Long.toString(time);
            } else {
                data[i] = s.getData(i);
            }
        }
        Sample rewritten = new Sample(s.getSampleRow(), sampleMetadata, data);
        super.produce(rewritten, 0);
    }
```
6. 数据处理完后,把相应的数据处理为报告,这点不用太关注
```Java
        // Process configuration to build data exporters
        String key;
        ExporterConfiguration value;
        for (Map.Entry<String, ExporterConfiguration> entry : configuration.getExportConfigurations().entrySet()) {
            key = entry.getKey();
            value = entry.getValue();
            if (log.isInfoEnabled()) {
                log.info("Exporting data using exporter:'{}' of className:'{}'", key, value.getClassName());
            }
            exportData(sampleContext, key, value);
        }
```

## 相关的重要类`CsvFileSampleSource`,`NormalizerSampleConsumer`,`Sample`,`SampleMetadata`,依次关系为`处理数据源`-->`标准化格式`-->`原型`

## 持久化处理
持久化处理,最好是建立一个NormalizerSample的Entry,在`NormalizerSampleConsumer`把相关的`Sample`转化为对应的`Entry`,并储存到数据库,不用源代码中的报告输入方法,直接储存到数据的数据进行集合整理.Entry额外属性除了`NormalizerSampleConsumer`的相关属性外,还要必须带有*.jtl文件的`@id`,以方便后续查找